{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SH3_MODELING_NET.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goifr_ApxKTr",
        "outputId": "ac59695f-244a-40e0-d13c-07177b74475c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Bio in /usr/local/lib/python3.7/dist-packages (1.3.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from Bio) (2.23.0)\n",
            "Requirement already satisfied: mygene in /usr/local/lib/python3.7/dist-packages (from Bio) (3.2.2)\n",
            "Requirement already satisfied: biopython>=1.79 in /usr/local/lib/python3.7/dist-packages (from Bio) (1.79)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from Bio) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from biopython>=1.79->Bio) (1.21.6)\n",
            "Requirement already satisfied: biothings-client>=0.2.6 in /usr/local/lib/python3.7/dist-packages (from mygene->Bio) (0.2.6)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->Bio) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->Bio) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->Bio) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->Bio) (3.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: import-ipynb in /usr/local/lib/python3.7/dist-packages (0.1.4)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (from import-ipynb) (5.5.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from import-ipynb) (5.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (57.4.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (0.8.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (5.1.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (4.8.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->import-ipynb) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->import-ipynb) (0.2.5)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->import-ipynb) (4.3.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->import-ipynb) (2.15.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat->import-ipynb) (4.10.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.18.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (4.11.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (4.2.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (21.4.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (5.7.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->import-ipynb) (3.8.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->IPython->import-ipynb) (0.7.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install Bio\n",
        "!pip install import-ipynb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MJmho3dxevJ",
        "outputId": "6c04ccf9-c930-45aa-eec5-4a30757c327a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# so we can import utils notebook (delete if working on Pycharm), you might need to change it to your working directory path\n",
        "%cd \"/content/drive/MyDrive/Colab Notebooks\" \n",
        "import import_ipynb\n",
        "import SH3_MODELING_utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKnp8_kQxRz5",
        "outputId": "e695b156-8297-4a72-cdcb-2da39f3e2ffe"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################################\n",
        "#                                                                             #\n",
        "#              Parameters you can change, but don't have to                   #\n",
        "#                                                                             #\n",
        "###############################################################################\n",
        "\n",
        "\n",
        "# number of ResNet blocks for the first ResNet and the kernel size.\n",
        "RESNET_1_BLOCKS = 3 \n",
        "RESNET_1_KERNEL_SIZE = 15\n",
        "RESNET_1_KERNEL_NUM = 64\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "#                                                                             #\n",
        "#                        Parameters you need to choose                        #\n",
        "#                                                                             #\n",
        "###############################################################################\n",
        "\n",
        "\n",
        "# number of ResNet blocks for the second ResNet, dilation list to repeat and the kernel size.\n",
        "\n",
        "RESNET_2_BLOCKS = 1 \n",
        "RESNET_2_KERNEL_SIZE = 5  # good start may be 3/5\n",
        "RESNET_2_KERNEL_NUM = 64\n",
        "DILATION = [1,2,4,8,16]\n",
        "\n",
        "# percentage of dropout for the dropout layer\n",
        "DROPOUT = 0.2 # good start may be 0.1-0.5\n",
        "\n",
        "# number of epochs, Learning rate and Batch size\n",
        "EPOCHS = 200\n",
        "LR = 0.001 # good start may be 0.0001/0.001/0.01\n",
        "BATCH = 16 # good start may be 32/64/128"
      ],
      "metadata": {
        "id": "COYjy1-Ax_ap"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet_1(input_layer):  # TODO: implement this!\n",
        "    \"\"\"\n",
        "    ResNet layer - input -> BatchNormalization -> Conv1D -> Relu -> BatchNormalization -> Conv1D -> Relu -> Add\n",
        "    :param input_layer: input layer for the ResNet\n",
        "    :return: last layer of the ResNet\n",
        "    \"\"\"\n",
        "    for i in range(RESNET_1_BLOCKS):\n",
        "      batch1_layer = tf.keras.layers.BatchNormalization()(input_layer)\n",
        "      conv1d1_layer = layers.Conv1D(RESNET_1_KERNEL_NUM,RESNET_1_KERNEL_SIZE,padding='same')(batch1_layer)\n",
        "      activation1_layer = layers.Activation(\"relu\")(conv1d1_layer)\n",
        "\n",
        "      batch2_layer = tf.keras.layers.BatchNormalization()(activation1_layer)\n",
        "      conv1d2_layer = layers.Conv1D(RESNET_1_KERNEL_NUM,RESNET_1_KERNEL_SIZE,padding='same')(batch2_layer)\n",
        "      activation2_layer = layers.Activation(\"relu\")(conv1d2_layer)\n",
        "      input_layer = tf.keras.layers.Add()([input_layer,activation2_layer])\n",
        "    return input_layer"
      ],
      "metadata": {
        "id": "xkCx4eZoyDCA"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet_2(input_layer):  # TODO: implement this!\n",
        "    \"\"\"\n",
        "    Dilated ResNet layer - input -> BatchNormalization -> dilated Conv1D -> Relu -> BatchNormalization -> dilated Conv1D -> Relu -> Add\n",
        "    :param input_layer: input layer for the ResNet\n",
        "    :return: last layer of the ResNet\n",
        "    \"\"\"\n",
        "    for i in range(RESNET_2_BLOCKS):\n",
        "      for j in DILATION:\n",
        "        batch1_layer = tf.keras.layers.BatchNormalization()(input_layer)\n",
        "        conv1d1_layer = layers.Conv1D(RESNET_2_KERNEL_NUM,RESNET_2_KERNEL_SIZE,padding='same',dilation_rate=j)(batch1_layer)\n",
        "        activation1_layer = layers.Activation(\"relu\")(conv1d1_layer)\n",
        "\n",
        "        batch2_layer = tf.keras.layers.BatchNormalization()(activation1_layer)\n",
        "        conv1d2_layer = layers.Conv1D(RESNET_2_KERNEL_NUM,RESNET_2_KERNEL_SIZE,padding='same',dilation_rate=j)(batch2_layer)\n",
        "        activation2_layer = layers.Activation(\"relu\")(conv1d2_layer)\n",
        "        input_layer = tf.keras.layers.Add()([input_layer,activation2_layer])\n",
        "    return input_layer"
      ],
      "metadata": {
        "id": "5mREtxnP7VwS"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_network():\n",
        "    \"\"\"\n",
        "    builds the neural network architecture as shown in the exercise.\n",
        "    :return: a Keras Model\n",
        "    \"\"\"\n",
        "    # input, shape (NB_MAX_LENGTH,FEATURE_NUM)\n",
        "    input_layer = tf.keras.Input(shape=(SH3_MODELING_utils.MAX_LENGTH_D + SH3_MODELING_utils.MAX_LENGTH_P, SH3_MODELING_utils.FEATURE_NUM))\n",
        "\n",
        "    # Conv1D -> shape = (NB_MAX_LENGTH, RESNET_1_KERNEL_NUM)\n",
        "    conv1d_layer = layers.Conv1D(RESNET_1_KERNEL_NUM, RESNET_1_KERNEL_SIZE, padding='same')(input_layer)\n",
        "\n",
        "    # first ResNet -> shape = (NB_MAX_LENGTH, RESNET_1_KERNEL_NUM)\n",
        "    resnet_layer = resnet_1(conv1d_layer)\n",
        "\n",
        "    # Conv1D -> shape = (NB_MAX_LENGTH, RESNET_2_KERNEL_NUM)\n",
        "    conv1d_layer = layers.Conv1D(RESNET_2_KERNEL_NUM, RESNET_2_KERNEL_SIZE, padding=\"same\")(resnet_layer)\n",
        "\n",
        "    # second ResNet -> shape = (NB_MAX_LENGTH, RESNET_2_KERNEL_NUM)\n",
        "    resnet_layer = resnet_2(conv1d_layer)\n",
        "\n",
        "\n",
        "    # TODO: fill the missing layers\n",
        "\n",
        "    dropout_layer = tf.keras.layers.Dropout(DROPOUT)(resnet_layer)\n",
        "\n",
        "    conv1d2_layer = layers.Conv1D(RESNET_2_KERNEL_NUM/2,RESNET_2_KERNEL_SIZE,padding='same')(dropout_layer)\n",
        "    activation_layer = layers.Activation(\"elu\")(conv1d2_layer)\n",
        "\n",
        "    output_layer = tf.keras.layers.Dense(15)(activation_layer)\n",
        "\n",
        "    model = tf.keras.Model(input_layer,output_layer)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "fqYC_Kzu7Yct"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_val_train_loss(history):\n",
        "    \"\"\"\n",
        "    plots the train and validation loss of the model at each epoch, saves it in 'model_loss_history.png'\n",
        "    :param history: history object (output of fit function)\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    ig, axes = plt.subplots(1, 1, figsize=(15,3))\n",
        "    axes.plot(history.history['loss'], label='Training loss')\n",
        "    axes.plot(history.history['val_loss'], label='Validation loss')\n",
        "    axes.legend()\n",
        "    axes.set_title(\"Train and Val MSE loss\")\n",
        "\n",
        "    plt.savefig(\"/content/drive/MyDrive/3D protein Hackathon/model_loss_history\")  # TODO: you can change the path here\n"
      ],
      "metadata": {
        "id": "8jph8ZcY7at3"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    model = build_network()\n",
        "    data_dir =\"/content/drive/MyDrive/3D protein Hackathon\"\n",
        "\n",
        "    # you can load here your input and output data\n",
        "\n",
        "    # X = numpy array of shape (1974,NB_MAX_LENGTH,FEATURE_NUM) of all the data input.\n",
        "    # Y = numpy array of shape (1974,NB_MAX_LENGTH,OUTPUT_SIZE) of all the data labels.\n",
        "    X_train = np.load(\"/content/drive/MyDrive/3D protein Hackathon/train_input.npy\")\n",
        "    y_train = np.load(\"/content/drive/MyDrive/3D protein Hackathon/train_labels.npy\")\n",
        "\n",
        "    X_test = np.load(\"/content/drive/MyDrive/3D protein Hackathon/test_input.npy\")\n",
        "    y_test = np.load(\"/content/drive/MyDrive/3D protein Hackathon/test_labels.npy\")\n",
        "\n",
        "    # split into validation and test sets as you like\n",
        "    # X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
        "    \n",
        "\n",
        "    # b)\n",
        "    #  compile model using Adam optimizer (with learning rate of your choice) and MSE loss.\n",
        "    my_optimizer = tf.keras.optimizers.Adam(learning_rate=LR)\n",
        "    model.compile(optimizer = my_optimizer, loss='mean_squared_error')\n",
        "\n",
        "\n",
        "    # c)\n",
        "    # fit model (use EPOCH for epoch parameter and BATCH for batch_size parameter)\n",
        "    # checkpoint_filepath = '/content/drive/MyDrive/Ex4Files/checkpoint'\n",
        "    # model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    # filepath=checkpoint_filepath,\n",
        "    # save_weights_only=True,\n",
        "    # monitor='val_loss',\n",
        "    # mode=min,\n",
        "    # save_best_only=True)\n",
        "    save_model = tf.keras.callbacks.ModelCheckpoint(filepath=f\"{data_dir}/sh3_model_second\", save_best_only=True, verbose=1)\n",
        "    \n",
        "    history = model.fit(X_train,y_train,epochs = EPOCHS, batch_size = BATCH, validation_data=(X_test,y_test),callbacks=[save_model])\n",
        "    plot_val_train_loss(history)\n",
        "\n",
        "    # d)\n",
        "    # save model\n",
        "    # model.load_weights(checkpoint_filepath)\n",
        "    print(model.summary())\n",
        "    # save_model.save(\"/content/drive/MyDrive/3D protein Hackathon/sh3_model\",save_format = 'tf')\n",
        "\n",
        "    # part 3 predict\n",
        "    score = model.evaluate(X_test, y_test) \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SpaQ6o1A7jYV",
        "outputId": "c6fd86a9-d3bf-4fec-f8cc-1781090b84cc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 2916.9260\n",
            "Epoch 1: val_loss improved from inf to 13315.66699, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 18s 1s/step - loss: 2845.4905 - val_loss: 13315.6670\n",
            "Epoch 2/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 697.3177\n",
            "Epoch 2: val_loss improved from 13315.66699 to 1830.24036, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 1s/step - loss: 652.6841 - val_loss: 1830.2404\n",
            "Epoch 3/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 297.3154\n",
            "Epoch 3: val_loss did not improve from 1830.24036\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 297.3154 - val_loss: 1856.0988\n",
            "Epoch 4/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 225.3686\n",
            "Epoch 4: val_loss did not improve from 1830.24036\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 220.5471 - val_loss: 2124.4695\n",
            "Epoch 5/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 193.2352\n",
            "Epoch 5: val_loss improved from 1830.24036 to 1528.49768, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 9s 1s/step - loss: 191.5587 - val_loss: 1528.4977\n",
            "Epoch 6/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 174.5712\n",
            "Epoch 6: val_loss improved from 1528.49768 to 1206.51001, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 1s/step - loss: 174.5712 - val_loss: 1206.5100\n",
            "Epoch 7/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 160.5342\n",
            "Epoch 7: val_loss improved from 1206.51001 to 1104.93152, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 1s/step - loss: 160.1627 - val_loss: 1104.9315\n",
            "Epoch 8/200\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 148.9322\n",
            "Epoch 8: val_loss improved from 1104.93152 to 1020.09790, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 9s 1s/step - loss: 149.3728 - val_loss: 1020.0979\n",
            "Epoch 9/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 143.1328\n",
            "Epoch 9: val_loss improved from 1020.09790 to 784.55829, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 1s/step - loss: 143.5353 - val_loss: 784.5583\n",
            "Epoch 10/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 141.3729\n",
            "Epoch 10: val_loss improved from 784.55829 to 783.20874, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 1s/step - loss: 141.3729 - val_loss: 783.2087\n",
            "Epoch 11/200\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 125.9601\n",
            "Epoch 11: val_loss improved from 783.20874 to 745.96222, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 9s 1s/step - loss: 125.5866 - val_loss: 745.9622\n",
            "Epoch 12/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 119.8592\n",
            "Epoch 12: val_loss did not improve from 745.96222\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 119.6326 - val_loss: 795.5989\n",
            "Epoch 13/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 117.8299\n",
            "Epoch 13: val_loss improved from 745.96222 to 720.02716, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 1s/step - loss: 116.3594 - val_loss: 720.0272\n",
            "Epoch 14/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 106.9404\n",
            "Epoch 14: val_loss improved from 720.02716 to 578.90643, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 969ms/step - loss: 106.9404 - val_loss: 578.9064\n",
            "Epoch 15/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 99.9722 \n",
            "Epoch 15: val_loss improved from 578.90643 to 559.04474, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 9s 1s/step - loss: 99.0937 - val_loss: 559.0447\n",
            "Epoch 16/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 95.6617\n",
            "Epoch 16: val_loss improved from 559.04474 to 512.24414, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 1s/step - loss: 95.6617 - val_loss: 512.2441\n",
            "Epoch 17/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 91.5357\n",
            "Epoch 17: val_loss improved from 512.24414 to 504.62918, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 1s/step - loss: 92.1564 - val_loss: 504.6292\n",
            "Epoch 18/200\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 86.8071\n",
            "Epoch 18: val_loss improved from 504.62918 to 429.44260, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 1s/step - loss: 86.7579 - val_loss: 429.4426\n",
            "Epoch 19/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 85.9530\n",
            "Epoch 19: val_loss improved from 429.44260 to 427.18738, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 955ms/step - loss: 85.9530 - val_loss: 427.1874\n",
            "Epoch 20/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 80.6193\n",
            "Epoch 20: val_loss did not improve from 427.18738\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 80.6606 - val_loss: 483.0394\n",
            "Epoch 21/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 79.9878\n",
            "Epoch 21: val_loss improved from 427.18738 to 423.22055, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 9s 1s/step - loss: 81.0990 - val_loss: 423.2206\n",
            "Epoch 22/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 78.2007\n",
            "Epoch 22: val_loss improved from 423.22055 to 374.21280, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 1s/step - loss: 78.2007 - val_loss: 374.2128\n",
            "Epoch 23/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 73.3745\n",
            "Epoch 23: val_loss did not improve from 374.21280\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 73.2385 - val_loss: 392.8270\n",
            "Epoch 24/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 71.6883\n",
            "Epoch 24: val_loss improved from 374.21280 to 326.19809, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 956ms/step - loss: 71.6883 - val_loss: 326.1981\n",
            "Epoch 25/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 68.9108\n",
            "Epoch 25: val_loss improved from 326.19809 to 308.93314, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 9s 1s/step - loss: 69.0403 - val_loss: 308.9331\n",
            "Epoch 26/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 67.7727\n",
            "Epoch 26: val_loss improved from 308.93314 to 267.31345, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 1s/step - loss: 67.7727 - val_loss: 267.3134\n",
            "Epoch 27/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 66.9549\n",
            "Epoch 27: val_loss did not improve from 267.31345\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 66.0715 - val_loss: 270.3703\n",
            "Epoch 28/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 68.0450\n",
            "Epoch 28: val_loss improved from 267.31345 to 252.50488, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 961ms/step - loss: 68.0450 - val_loss: 252.5049\n",
            "Epoch 29/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 64.7351\n",
            "Epoch 29: val_loss improved from 252.50488 to 241.96342, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 9s 1s/step - loss: 64.5752 - val_loss: 241.9634\n",
            "Epoch 30/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 64.8643\n",
            "Epoch 30: val_loss improved from 241.96342 to 208.35420, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 1s/step - loss: 64.9529 - val_loss: 208.3542\n",
            "Epoch 31/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 64.2334\n",
            "Epoch 31: val_loss did not improve from 208.35420\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 63.6509 - val_loss: 221.6803\n",
            "Epoch 32/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 61.8804\n",
            "Epoch 32: val_loss improved from 208.35420 to 189.88780, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 9s 1s/step - loss: 61.3103 - val_loss: 189.8878\n",
            "Epoch 33/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 60.2260\n",
            "Epoch 33: val_loss did not improve from 189.88780\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 60.2260 - val_loss: 194.3044\n",
            "Epoch 34/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 60.9467\n",
            "Epoch 34: val_loss improved from 189.88780 to 129.72719, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 9s 1s/step - loss: 60.9467 - val_loss: 129.7272\n",
            "Epoch 35/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 61.2987\n",
            "Epoch 35: val_loss did not improve from 129.72719\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 61.7299 - val_loss: 140.0102\n",
            "Epoch 36/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 59.3722\n",
            "Epoch 36: val_loss did not improve from 129.72719\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 58.5615 - val_loss: 151.9726\n",
            "Epoch 37/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 57.8589\n",
            "Epoch 37: val_loss did not improve from 129.72719\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 57.9719 - val_loss: 175.9031\n",
            "Epoch 38/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 57.8615\n",
            "Epoch 38: val_loss improved from 129.72719 to 120.13702, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 1s/step - loss: 57.9620 - val_loss: 120.1370\n",
            "Epoch 39/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 54.8382\n",
            "Epoch 39: val_loss improved from 120.13702 to 102.81712, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 951ms/step - loss: 55.6826 - val_loss: 102.8171\n",
            "Epoch 40/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 61.5515\n",
            "Epoch 40: val_loss improved from 102.81712 to 74.24820, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 9s 1s/step - loss: 60.8270 - val_loss: 74.2482\n",
            "Epoch 41/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 57.9329\n",
            "Epoch 41: val_loss did not improve from 74.24820\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 57.9223 - val_loss: 80.3080\n",
            "Epoch 42/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 53.8763\n",
            "Epoch 42: val_loss did not improve from 74.24820\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 53.1145 - val_loss: 99.1425\n",
            "Epoch 43/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 49.3312\n",
            "Epoch 43: val_loss did not improve from 74.24820\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 49.3312 - val_loss: 87.9324\n",
            "Epoch 44/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 46.7635\n",
            "Epoch 44: val_loss did not improve from 74.24820\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 46.0624 - val_loss: 86.1714\n",
            "Epoch 45/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 44.0033\n",
            "Epoch 45: val_loss did not improve from 74.24820\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 44.0033 - val_loss: 78.1585\n",
            "Epoch 46/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 41.6798\n",
            "Epoch 46: val_loss improved from 74.24820 to 56.06706, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 1s/step - loss: 42.0408 - val_loss: 56.0671\n",
            "Epoch 47/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 39.2819\n",
            "Epoch 47: val_loss did not improve from 56.06706\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 38.6053 - val_loss: 72.0421\n",
            "Epoch 48/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 36.4069\n",
            "Epoch 48: val_loss did not improve from 56.06706\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 35.8163 - val_loss: 90.5658\n",
            "Epoch 49/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 34.6370\n",
            "Epoch 49: val_loss improved from 56.06706 to 53.86651, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 1s/step - loss: 34.1533 - val_loss: 53.8665\n",
            "Epoch 50/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 30.9312\n",
            "Epoch 50: val_loss improved from 53.86651 to 33.67921, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 1s/step - loss: 30.6751 - val_loss: 33.6792\n",
            "Epoch 51/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 29.3967\n",
            "Epoch 51: val_loss improved from 33.67921 to 32.96079, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 1s/step - loss: 29.4368 - val_loss: 32.9608\n",
            "Epoch 52/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 26.6495\n",
            "Epoch 52: val_loss did not improve from 32.96079\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 26.2268 - val_loss: 53.1655\n",
            "Epoch 53/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 25.5226\n",
            "Epoch 53: val_loss improved from 32.96079 to 29.58340, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 1s/step - loss: 25.5226 - val_loss: 29.5834\n",
            "Epoch 54/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 23.8730\n",
            "Epoch 54: val_loss improved from 29.58340 to 24.12469, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 1s/step - loss: 24.1419 - val_loss: 24.1247\n",
            "Epoch 55/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 24.4407\n",
            "Epoch 55: val_loss did not improve from 24.12469\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 24.0739 - val_loss: 59.6524\n",
            "Epoch 56/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 24.0917\n",
            "Epoch 56: val_loss did not improve from 24.12469\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 24.0742 - val_loss: 46.9687\n",
            "Epoch 57/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 25.5151\n",
            "Epoch 57: val_loss improved from 24.12469 to 17.81309, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 1s/step - loss: 25.0787 - val_loss: 17.8131\n",
            "Epoch 58/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 24.0898\n",
            "Epoch 58: val_loss did not improve from 17.81309\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 23.8219 - val_loss: 20.5646\n",
            "Epoch 59/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 21.6419\n",
            "Epoch 59: val_loss improved from 17.81309 to 16.07684, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 952ms/step - loss: 21.6419 - val_loss: 16.0768\n",
            "Epoch 60/200\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 21.2857\n",
            "Epoch 60: val_loss did not improve from 16.07684\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 21.2013 - val_loss: 24.2579\n",
            "Epoch 61/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 20.5046\n",
            "Epoch 61: val_loss did not improve from 16.07684\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 20.5072 - val_loss: 19.5465\n",
            "Epoch 62/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 20.6080\n",
            "Epoch 62: val_loss improved from 16.07684 to 12.58667, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 9s 1s/step - loss: 20.6244 - val_loss: 12.5867\n",
            "Epoch 63/200\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 22.9657\n",
            "Epoch 63: val_loss did not improve from 12.58667\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 22.8025 - val_loss: 17.2069\n",
            "Epoch 64/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 19.7727\n",
            "Epoch 64: val_loss did not improve from 12.58667\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 19.6605 - val_loss: 22.5498\n",
            "Epoch 65/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 19.5877\n",
            "Epoch 65: val_loss did not improve from 12.58667\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 19.7690 - val_loss: 16.7904\n",
            "Epoch 66/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 19.0727\n",
            "Epoch 66: val_loss improved from 12.58667 to 11.88959, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 1s/step - loss: 19.1074 - val_loss: 11.8896\n",
            "Epoch 67/200\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 20.3637\n",
            "Epoch 67: val_loss did not improve from 11.88959\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 20.2389 - val_loss: 12.0485\n",
            "Epoch 68/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 18.7712\n",
            "Epoch 68: val_loss did not improve from 11.88959\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 18.8545 - val_loss: 15.7793\n",
            "Epoch 69/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 19.1451\n",
            "Epoch 69: val_loss did not improve from 11.88959\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 19.3936 - val_loss: 15.6773\n",
            "Epoch 70/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 19.1737\n",
            "Epoch 70: val_loss did not improve from 11.88959\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 18.8385 - val_loss: 12.3170\n",
            "Epoch 71/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 18.0655\n",
            "Epoch 71: val_loss improved from 11.88959 to 9.54926, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 958ms/step - loss: 18.0655 - val_loss: 9.5493\n",
            "Epoch 72/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 17.3460\n",
            "Epoch 72: val_loss did not improve from 9.54926\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 17.3471 - val_loss: 18.4260\n",
            "Epoch 73/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 16.4403\n",
            "Epoch 73: val_loss did not improve from 9.54926\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 16.5548 - val_loss: 11.7347\n",
            "Epoch 74/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 17.2660\n",
            "Epoch 74: val_loss did not improve from 9.54926\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 17.1345 - val_loss: 9.6689\n",
            "Epoch 75/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 16.7493\n",
            "Epoch 75: val_loss did not improve from 9.54926\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 16.5617 - val_loss: 14.2126\n",
            "Epoch 76/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 17.0378\n",
            "Epoch 76: val_loss did not improve from 9.54926\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 17.0443 - val_loss: 11.4289\n",
            "Epoch 77/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 16.2070\n",
            "Epoch 77: val_loss did not improve from 9.54926\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 16.2244 - val_loss: 10.9908\n",
            "Epoch 78/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 15.8904\n",
            "Epoch 78: val_loss did not improve from 9.54926\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 15.7785 - val_loss: 9.8763\n",
            "Epoch 79/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 15.2634\n",
            "Epoch 79: val_loss improved from 9.54926 to 7.59439, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 9s 1s/step - loss: 15.4340 - val_loss: 7.5944\n",
            "Epoch 80/200\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 16.6818\n",
            "Epoch 80: val_loss did not improve from 7.59439\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 16.5471 - val_loss: 7.7891\n",
            "Epoch 81/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 14.8135\n",
            "Epoch 81: val_loss did not improve from 7.59439\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 14.6886 - val_loss: 9.0492\n",
            "Epoch 82/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 15.1521\n",
            "Epoch 82: val_loss improved from 7.59439 to 7.28659, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 1s/step - loss: 15.4387 - val_loss: 7.2866\n",
            "Epoch 83/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 15.5348\n",
            "Epoch 83: val_loss did not improve from 7.28659\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 15.3708 - val_loss: 8.9564\n",
            "Epoch 84/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 14.0799\n",
            "Epoch 84: val_loss did not improve from 7.28659\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 14.0799 - val_loss: 7.4190\n",
            "Epoch 85/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 14.0951\n",
            "Epoch 85: val_loss improved from 7.28659 to 6.89196, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 1s/step - loss: 14.1238 - val_loss: 6.8920\n",
            "Epoch 86/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 13.4422\n",
            "Epoch 86: val_loss improved from 6.89196 to 6.87443, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 1s/step - loss: 13.4525 - val_loss: 6.8744\n",
            "Epoch 87/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 13.5576\n",
            "Epoch 87: val_loss did not improve from 6.87443\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 13.6053 - val_loss: 6.8817\n",
            "Epoch 88/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 13.7834\n",
            "Epoch 88: val_loss did not improve from 6.87443\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 13.8243 - val_loss: 10.3485\n",
            "Epoch 89/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 15.3255\n",
            "Epoch 89: val_loss did not improve from 6.87443\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 15.0632 - val_loss: 11.1691\n",
            "Epoch 90/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 15.4694\n",
            "Epoch 90: val_loss did not improve from 6.87443\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 15.1190 - val_loss: 9.0853\n",
            "Epoch 91/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 17.4422\n",
            "Epoch 91: val_loss did not improve from 6.87443\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 17.0723 - val_loss: 10.2456\n",
            "Epoch 92/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 14.5623\n",
            "Epoch 92: val_loss did not improve from 6.87443\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 14.5623 - val_loss: 9.2287\n",
            "Epoch 93/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 13.4836\n",
            "Epoch 93: val_loss did not improve from 6.87443\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 13.4836 - val_loss: 7.8851\n",
            "Epoch 94/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 12.7413\n",
            "Epoch 94: val_loss improved from 6.87443 to 6.84588, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 947ms/step - loss: 12.5588 - val_loss: 6.8459\n",
            "Epoch 95/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 13.1703\n",
            "Epoch 95: val_loss did not improve from 6.84588\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 13.1703 - val_loss: 9.0955\n",
            "Epoch 96/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 12.9806\n",
            "Epoch 96: val_loss improved from 6.84588 to 6.12015, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 1s/step - loss: 12.7815 - val_loss: 6.1202\n",
            "Epoch 97/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 12.3944\n",
            "Epoch 97: val_loss did not improve from 6.12015\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 12.2368 - val_loss: 8.6844\n",
            "Epoch 98/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 12.1958\n",
            "Epoch 98: val_loss improved from 6.12015 to 6.11909, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 1s/step - loss: 12.1958 - val_loss: 6.1191\n",
            "Epoch 99/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 11.6961\n",
            "Epoch 99: val_loss improved from 6.11909 to 5.63606, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 1s/step - loss: 11.7972 - val_loss: 5.6361\n",
            "Epoch 100/200\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 11.7843\n",
            "Epoch 100: val_loss did not improve from 5.63606\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 12.0513 - val_loss: 6.0959\n",
            "Epoch 101/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 13.5999\n",
            "Epoch 101: val_loss improved from 5.63606 to 5.51773, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 1s/step - loss: 13.9248 - val_loss: 5.5177\n",
            "Epoch 102/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 12.8728\n",
            "Epoch 102: val_loss did not improve from 5.51773\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 12.8728 - val_loss: 5.8273\n",
            "Epoch 103/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 12.7666\n",
            "Epoch 103: val_loss did not improve from 5.51773\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 12.5151 - val_loss: 5.5180\n",
            "Epoch 104/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 11.2631\n",
            "Epoch 104: val_loss did not improve from 5.51773\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 11.1191 - val_loss: 6.7679\n",
            "Epoch 105/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 11.1011\n",
            "Epoch 105: val_loss improved from 5.51773 to 5.45558, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 1s/step - loss: 11.1337 - val_loss: 5.4556\n",
            "Epoch 106/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 11.3808\n",
            "Epoch 106: val_loss did not improve from 5.45558\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 11.4465 - val_loss: 6.7004\n",
            "Epoch 107/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 11.6515\n",
            "Epoch 107: val_loss did not improve from 5.45558\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 11.3691 - val_loss: 5.5550\n",
            "Epoch 108/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 11.0522\n",
            "Epoch 108: val_loss did not improve from 5.45558\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 11.0522 - val_loss: 7.8546\n",
            "Epoch 109/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 11.2542\n",
            "Epoch 109: val_loss improved from 5.45558 to 5.19230, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 963ms/step - loss: 11.2203 - val_loss: 5.1923\n",
            "Epoch 110/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 11.1716\n",
            "Epoch 110: val_loss improved from 5.19230 to 5.12315, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 9s 1s/step - loss: 11.6084 - val_loss: 5.1231\n",
            "Epoch 111/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 10.1341\n",
            "Epoch 111: val_loss did not improve from 5.12315\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 10.4020 - val_loss: 6.9137\n",
            "Epoch 112/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 11.7534\n",
            "Epoch 112: val_loss did not improve from 5.12315\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 11.9617 - val_loss: 7.0745\n",
            "Epoch 113/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 12.3234\n",
            "Epoch 113: val_loss improved from 5.12315 to 4.80498, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 1s/step - loss: 11.9914 - val_loss: 4.8050\n",
            "Epoch 114/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 11.4147\n",
            "Epoch 114: val_loss did not improve from 4.80498\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 11.2593 - val_loss: 5.1249\n",
            "Epoch 115/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 11.0484\n",
            "Epoch 115: val_loss improved from 4.80498 to 4.72078, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 1s/step - loss: 11.0484 - val_loss: 4.7208\n",
            "Epoch 116/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 11.1537\n",
            "Epoch 116: val_loss did not improve from 4.72078\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 10.9591 - val_loss: 7.1933\n",
            "Epoch 117/200\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 12.3734\n",
            "Epoch 117: val_loss did not improve from 4.72078\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 12.1923 - val_loss: 9.2263\n",
            "Epoch 118/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 12.0399\n",
            "Epoch 118: val_loss did not improve from 4.72078\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 11.7921 - val_loss: 5.8872\n",
            "Epoch 119/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 9.9642\n",
            "Epoch 119: val_loss did not improve from 4.72078\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 9.9983 - val_loss: 5.5722\n",
            "Epoch 120/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 9.9984 \n",
            "Epoch 120: val_loss did not improve from 4.72078\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 9.9984 - val_loss: 6.6104\n",
            "Epoch 121/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 10.4154\n",
            "Epoch 121: val_loss did not improve from 4.72078\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 10.3150 - val_loss: 6.9067\n",
            "Epoch 122/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 9.5135\n",
            "Epoch 122: val_loss did not improve from 4.72078\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 9.4118 - val_loss: 4.8182\n",
            "Epoch 123/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 10.1600\n",
            "Epoch 123: val_loss did not improve from 4.72078\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 9.9852 - val_loss: 5.0285\n",
            "Epoch 124/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 9.4897\n",
            "Epoch 124: val_loss did not improve from 4.72078\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 9.3851 - val_loss: 5.4858\n",
            "Epoch 125/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 9.4703\n",
            "Epoch 125: val_loss did not improve from 4.72078\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 9.4703 - val_loss: 4.8945\n",
            "Epoch 126/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 9.5763\n",
            "Epoch 126: val_loss did not improve from 4.72078\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 9.5524 - val_loss: 5.1567\n",
            "Epoch 127/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 9.8754 \n",
            "Epoch 127: val_loss did not improve from 4.72078\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 9.8352 - val_loss: 4.8190\n",
            "Epoch 128/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 9.9475\n",
            "Epoch 128: val_loss did not improve from 4.72078\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 9.7088 - val_loss: 4.8967\n",
            "Epoch 129/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 9.7157 \n",
            "Epoch 129: val_loss improved from 4.72078 to 4.62449, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 942ms/step - loss: 9.6074 - val_loss: 4.6245\n",
            "Epoch 130/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 9.0194\n",
            "Epoch 130: val_loss improved from 4.62449 to 4.46729, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 9s 1s/step - loss: 9.0194 - val_loss: 4.4673\n",
            "Epoch 131/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 9.1847\n",
            "Epoch 131: val_loss did not improve from 4.46729\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 9.0542 - val_loss: 4.5520\n",
            "Epoch 132/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 9.2285\n",
            "Epoch 132: val_loss did not improve from 4.46729\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 9.1146 - val_loss: 5.2888\n",
            "Epoch 133/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 9.7029\n",
            "Epoch 133: val_loss did not improve from 4.46729\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 9.6010 - val_loss: 4.5612\n",
            "Epoch 134/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 8.6499\n",
            "Epoch 134: val_loss did not improve from 4.46729\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 8.8649 - val_loss: 5.6011\n",
            "Epoch 135/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 9.3560\n",
            "Epoch 135: val_loss did not improve from 4.46729\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 9.5732 - val_loss: 4.5762\n",
            "Epoch 136/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 9.7876\n",
            "Epoch 136: val_loss did not improve from 4.46729\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 9.6989 - val_loss: 4.6949\n",
            "Epoch 137/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 9.5065\n",
            "Epoch 137: val_loss did not improve from 4.46729\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 9.5065 - val_loss: 6.2864\n",
            "Epoch 138/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 10.1163\n",
            "Epoch 138: val_loss did not improve from 4.46729\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 10.0532 - val_loss: 4.5831\n",
            "Epoch 139/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 9.1170\n",
            "Epoch 139: val_loss did not improve from 4.46729\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 9.1176 - val_loss: 4.8220\n",
            "Epoch 140/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 8.6901\n",
            "Epoch 140: val_loss improved from 4.46729 to 4.44491, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 1s/step - loss: 8.7967 - val_loss: 4.4449\n",
            "Epoch 141/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 8.9746\n",
            "Epoch 141: val_loss did not improve from 4.44491\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 8.9746 - val_loss: 4.6654\n",
            "Epoch 142/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 8.7407\n",
            "Epoch 142: val_loss did not improve from 4.44491\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 8.9087 - val_loss: 4.4980\n",
            "Epoch 143/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 8.6756\n",
            "Epoch 143: val_loss did not improve from 4.44491\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 9.0106 - val_loss: 4.6706\n",
            "Epoch 144/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 8.7513\n",
            "Epoch 144: val_loss did not improve from 4.44491\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 8.6990 - val_loss: 4.5478\n",
            "Epoch 145/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 8.4021\n",
            "Epoch 145: val_loss did not improve from 4.44491\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 8.4021 - val_loss: 4.4486\n",
            "Epoch 146/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 8.6538\n",
            "Epoch 146: val_loss improved from 4.44491 to 4.39301, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 1s/step - loss: 8.5184 - val_loss: 4.3930\n",
            "Epoch 147/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 8.7809\n",
            "Epoch 147: val_loss improved from 4.39301 to 4.29804, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 1s/step - loss: 8.7525 - val_loss: 4.2980\n",
            "Epoch 148/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 8.3590\n",
            "Epoch 148: val_loss did not improve from 4.29804\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 8.4516 - val_loss: 4.4576\n",
            "Epoch 149/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 8.6203\n",
            "Epoch 149: val_loss did not improve from 4.29804\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 8.6203 - val_loss: 4.8130\n",
            "Epoch 150/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 8.5644\n",
            "Epoch 150: val_loss did not improve from 4.29804\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 8.5138 - val_loss: 4.5713\n",
            "Epoch 151/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 9.0762\n",
            "Epoch 151: val_loss did not improve from 4.29804\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 8.9178 - val_loss: 4.8033\n",
            "Epoch 152/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 9.0406\n",
            "Epoch 152: val_loss did not improve from 4.29804\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 9.0916 - val_loss: 4.7310\n",
            "Epoch 153/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 8.9750\n",
            "Epoch 153: val_loss did not improve from 4.29804\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 8.7928 - val_loss: 4.6919\n",
            "Epoch 154/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 8.9942\n",
            "Epoch 154: val_loss did not improve from 4.29804\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 8.9942 - val_loss: 4.8950\n",
            "Epoch 155/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 8.4267\n",
            "Epoch 155: val_loss did not improve from 4.29804\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 8.2925 - val_loss: 4.4782\n",
            "Epoch 156/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 8.8317\n",
            "Epoch 156: val_loss did not improve from 4.29804\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 8.7103 - val_loss: 4.5764\n",
            "Epoch 157/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 8.7903\n",
            "Epoch 157: val_loss did not improve from 4.29804\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 8.7903 - val_loss: 7.2619\n",
            "Epoch 158/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 9.3315\n",
            "Epoch 158: val_loss did not improve from 4.29804\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 9.3315 - val_loss: 6.7191\n",
            "Epoch 159/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 8.7699\n",
            "Epoch 159: val_loss did not improve from 4.29804\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 9.0974 - val_loss: 6.0886\n",
            "Epoch 160/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 8.1919\n",
            "Epoch 160: val_loss improved from 4.29804 to 4.16040, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 8s 951ms/step - loss: 8.3361 - val_loss: 4.1604\n",
            "Epoch 161/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 8.7140\n",
            "Epoch 161: val_loss did not improve from 4.16040\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 8.7140 - val_loss: 4.6053\n",
            "Epoch 162/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 10.3612\n",
            "Epoch 162: val_loss did not improve from 4.16040\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 10.3612 - val_loss: 5.0946\n",
            "Epoch 163/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 8.9573\n",
            "Epoch 163: val_loss did not improve from 4.16040\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 9.0310 - val_loss: 5.8576\n",
            "Epoch 164/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 8.5660\n",
            "Epoch 164: val_loss did not improve from 4.16040\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 8.5660 - val_loss: 5.8011\n",
            "Epoch 165/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 8.8439\n",
            "Epoch 165: val_loss did not improve from 4.16040\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 8.7603 - val_loss: 4.8651\n",
            "Epoch 166/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 8.3752\n",
            "Epoch 166: val_loss did not improve from 4.16040\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 8.2099 - val_loss: 4.3347\n",
            "Epoch 167/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 8.1465\n",
            "Epoch 167: val_loss did not improve from 4.16040\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 8.1006 - val_loss: 4.3056\n",
            "Epoch 168/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 8.0011\n",
            "Epoch 168: val_loss did not improve from 4.16040\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 7.9859 - val_loss: 4.3128\n",
            "Epoch 169/200\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 8.0511\n",
            "Epoch 169: val_loss did not improve from 4.16040\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 8.0816 - val_loss: 4.7074\n",
            "Epoch 170/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 8.2784\n",
            "Epoch 170: val_loss did not improve from 4.16040\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 8.3683 - val_loss: 4.8416\n",
            "Epoch 171/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 7.9648\n",
            "Epoch 171: val_loss did not improve from 4.16040\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 7.9314 - val_loss: 4.3303\n",
            "Epoch 172/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 8.1287\n",
            "Epoch 172: val_loss did not improve from 4.16040\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 7.9537 - val_loss: 4.3732\n",
            "Epoch 173/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 7.9256\n",
            "Epoch 173: val_loss did not improve from 4.16040\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 8.1152 - val_loss: 4.4867\n",
            "Epoch 174/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 8.1286\n",
            "Epoch 174: val_loss did not improve from 4.16040\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 8.2042 - val_loss: 4.7971\n",
            "Epoch 175/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 7.8923\n",
            "Epoch 175: val_loss did not improve from 4.16040\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 7.8923 - val_loss: 4.2401\n",
            "Epoch 176/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 7.8424\n",
            "Epoch 176: val_loss did not improve from 4.16040\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 7.6753 - val_loss: 5.6469\n",
            "Epoch 177/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 8.4913\n",
            "Epoch 177: val_loss did not improve from 4.16040\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 8.3071 - val_loss: 4.6787\n",
            "Epoch 178/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 8.1004\n",
            "Epoch 178: val_loss did not improve from 4.16040\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 8.1004 - val_loss: 5.1123\n",
            "Epoch 179/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 7.9590\n",
            "Epoch 179: val_loss did not improve from 4.16040\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 7.9590 - val_loss: 4.4028\n",
            "Epoch 180/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 7.8602\n",
            "Epoch 180: val_loss did not improve from 4.16040\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 7.8602 - val_loss: 4.3845\n",
            "Epoch 181/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 8.0395\n",
            "Epoch 181: val_loss did not improve from 4.16040\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 7.9303 - val_loss: 4.4374\n",
            "Epoch 182/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 7.7082\n",
            "Epoch 182: val_loss did not improve from 4.16040\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 7.7082 - val_loss: 5.4031\n",
            "Epoch 183/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 8.2646\n",
            "Epoch 183: val_loss did not improve from 4.16040\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 8.3064 - val_loss: 5.9503\n",
            "Epoch 184/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 9.6125\n",
            "Epoch 184: val_loss did not improve from 4.16040\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 9.6125 - val_loss: 6.0724\n",
            "Epoch 185/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 8.1458\n",
            "Epoch 185: val_loss did not improve from 4.16040\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 7.9307 - val_loss: 5.1792\n",
            "Epoch 186/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 7.6274\n",
            "Epoch 186: val_loss did not improve from 4.16040\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 7.6274 - val_loss: 5.3100\n",
            "Epoch 187/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 8.0671\n",
            "Epoch 187: val_loss did not improve from 4.16040\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 8.2738 - val_loss: 5.3634\n",
            "Epoch 188/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 7.9834\n",
            "Epoch 188: val_loss did not improve from 4.16040\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 7.9379 - val_loss: 4.8258\n",
            "Epoch 189/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 8.0976\n",
            "Epoch 189: val_loss did not improve from 4.16040\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 7.9229 - val_loss: 4.3649\n",
            "Epoch 190/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 7.6365\n",
            "Epoch 190: val_loss improved from 4.16040 to 4.11814, saving model to /content/drive/MyDrive/3D protein Hackathon/sh3_model_second\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/3D protein Hackathon/sh3_model_second/assets\n",
            "9/9 [==============================] - 9s 1s/step - loss: 7.6365 - val_loss: 4.1181\n",
            "Epoch 191/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 7.6093\n",
            "Epoch 191: val_loss did not improve from 4.11814\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 7.4723 - val_loss: 4.4068\n",
            "Epoch 192/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 7.8205\n",
            "Epoch 192: val_loss did not improve from 4.11814\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 7.8205 - val_loss: 4.5540\n",
            "Epoch 193/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 8.3833\n",
            "Epoch 193: val_loss did not improve from 4.11814\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 8.3833 - val_loss: 4.1807\n",
            "Epoch 194/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 7.6831\n",
            "Epoch 194: val_loss did not improve from 4.11814\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 7.6559 - val_loss: 4.3937\n",
            "Epoch 195/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 7.5608\n",
            "Epoch 195: val_loss did not improve from 4.11814\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 7.4255 - val_loss: 4.3030\n",
            "Epoch 196/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 7.4841\n",
            "Epoch 196: val_loss did not improve from 4.11814\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 7.6707 - val_loss: 4.3026\n",
            "Epoch 197/200\n",
            "9/9 [==============================] - ETA: 0s - loss: 8.3389\n",
            "Epoch 197: val_loss did not improve from 4.11814\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 8.3389 - val_loss: 5.3090\n",
            "Epoch 198/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 8.2331\n",
            "Epoch 198: val_loss did not improve from 4.11814\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 8.2172 - val_loss: 4.4198\n",
            "Epoch 199/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 7.5616\n",
            "Epoch 199: val_loss did not improve from 4.11814\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 7.6480 - val_loss: 4.9570\n",
            "Epoch 200/200\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 7.2359\n",
            "Epoch 200: val_loss did not improve from 4.11814\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 7.1630 - val_loss: 4.2683\n",
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_7 (InputLayer)           [(None, 160, 24)]    0           []                               \n",
            "                                                                                                  \n",
            " conv1d_276 (Conv1D)            (None, 160, 64)      23104       ['input_7[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_258 (Batch  (None, 160, 64)     256         ['conv1d_276[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv1d_277 (Conv1D)            (None, 160, 64)      61504       ['batch_normalization_258[0][0]']\n",
            "                                                                                                  \n",
            " activation_264 (Activation)    (None, 160, 64)      0           ['conv1d_277[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_259 (Batch  (None, 160, 64)     256         ['activation_264[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv1d_278 (Conv1D)            (None, 160, 64)      61504       ['batch_normalization_259[0][0]']\n",
            "                                                                                                  \n",
            " activation_265 (Activation)    (None, 160, 64)      0           ['conv1d_278[0][0]']             \n",
            "                                                                                                  \n",
            " add_129 (Add)                  (None, 160, 64)      0           ['conv1d_276[0][0]',             \n",
            "                                                                  'activation_265[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_260 (Batch  (None, 160, 64)     256         ['add_129[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv1d_279 (Conv1D)            (None, 160, 64)      61504       ['batch_normalization_260[0][0]']\n",
            "                                                                                                  \n",
            " activation_266 (Activation)    (None, 160, 64)      0           ['conv1d_279[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_261 (Batch  (None, 160, 64)     256         ['activation_266[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv1d_280 (Conv1D)            (None, 160, 64)      61504       ['batch_normalization_261[0][0]']\n",
            "                                                                                                  \n",
            " activation_267 (Activation)    (None, 160, 64)      0           ['conv1d_280[0][0]']             \n",
            "                                                                                                  \n",
            " add_130 (Add)                  (None, 160, 64)      0           ['add_129[0][0]',                \n",
            "                                                                  'activation_267[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_262 (Batch  (None, 160, 64)     256         ['add_130[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv1d_281 (Conv1D)            (None, 160, 64)      61504       ['batch_normalization_262[0][0]']\n",
            "                                                                                                  \n",
            " activation_268 (Activation)    (None, 160, 64)      0           ['conv1d_281[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_263 (Batch  (None, 160, 64)     256         ['activation_268[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv1d_282 (Conv1D)            (None, 160, 64)      61504       ['batch_normalization_263[0][0]']\n",
            "                                                                                                  \n",
            " activation_269 (Activation)    (None, 160, 64)      0           ['conv1d_282[0][0]']             \n",
            "                                                                                                  \n",
            " add_131 (Add)                  (None, 160, 64)      0           ['add_130[0][0]',                \n",
            "                                                                  'activation_269[0][0]']         \n",
            "                                                                                                  \n",
            " conv1d_283 (Conv1D)            (None, 160, 64)      20544       ['add_131[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_264 (Batch  (None, 160, 64)     256         ['conv1d_283[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv1d_284 (Conv1D)            (None, 160, 64)      20544       ['batch_normalization_264[0][0]']\n",
            "                                                                                                  \n",
            " activation_270 (Activation)    (None, 160, 64)      0           ['conv1d_284[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_265 (Batch  (None, 160, 64)     256         ['activation_270[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv1d_285 (Conv1D)            (None, 160, 64)      20544       ['batch_normalization_265[0][0]']\n",
            "                                                                                                  \n",
            " activation_271 (Activation)    (None, 160, 64)      0           ['conv1d_285[0][0]']             \n",
            "                                                                                                  \n",
            " add_132 (Add)                  (None, 160, 64)      0           ['conv1d_283[0][0]',             \n",
            "                                                                  'activation_271[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_266 (Batch  (None, 160, 64)     256         ['add_132[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv1d_286 (Conv1D)            (None, 160, 64)      20544       ['batch_normalization_266[0][0]']\n",
            "                                                                                                  \n",
            " activation_272 (Activation)    (None, 160, 64)      0           ['conv1d_286[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_267 (Batch  (None, 160, 64)     256         ['activation_272[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv1d_287 (Conv1D)            (None, 160, 64)      20544       ['batch_normalization_267[0][0]']\n",
            "                                                                                                  \n",
            " activation_273 (Activation)    (None, 160, 64)      0           ['conv1d_287[0][0]']             \n",
            "                                                                                                  \n",
            " add_133 (Add)                  (None, 160, 64)      0           ['add_132[0][0]',                \n",
            "                                                                  'activation_273[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_268 (Batch  (None, 160, 64)     256         ['add_133[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv1d_288 (Conv1D)            (None, 160, 64)      20544       ['batch_normalization_268[0][0]']\n",
            "                                                                                                  \n",
            " activation_274 (Activation)    (None, 160, 64)      0           ['conv1d_288[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_269 (Batch  (None, 160, 64)     256         ['activation_274[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv1d_289 (Conv1D)            (None, 160, 64)      20544       ['batch_normalization_269[0][0]']\n",
            "                                                                                                  \n",
            " activation_275 (Activation)    (None, 160, 64)      0           ['conv1d_289[0][0]']             \n",
            "                                                                                                  \n",
            " add_134 (Add)                  (None, 160, 64)      0           ['add_133[0][0]',                \n",
            "                                                                  'activation_275[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_270 (Batch  (None, 160, 64)     256         ['add_134[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv1d_290 (Conv1D)            (None, 160, 64)      20544       ['batch_normalization_270[0][0]']\n",
            "                                                                                                  \n",
            " activation_276 (Activation)    (None, 160, 64)      0           ['conv1d_290[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_271 (Batch  (None, 160, 64)     256         ['activation_276[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv1d_291 (Conv1D)            (None, 160, 64)      20544       ['batch_normalization_271[0][0]']\n",
            "                                                                                                  \n",
            " activation_277 (Activation)    (None, 160, 64)      0           ['conv1d_291[0][0]']             \n",
            "                                                                                                  \n",
            " add_135 (Add)                  (None, 160, 64)      0           ['add_134[0][0]',                \n",
            "                                                                  'activation_277[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_272 (Batch  (None, 160, 64)     256         ['add_135[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv1d_292 (Conv1D)            (None, 160, 64)      20544       ['batch_normalization_272[0][0]']\n",
            "                                                                                                  \n",
            " activation_278 (Activation)    (None, 160, 64)      0           ['conv1d_292[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_273 (Batch  (None, 160, 64)     256         ['activation_278[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv1d_293 (Conv1D)            (None, 160, 64)      20544       ['batch_normalization_273[0][0]']\n",
            "                                                                                                  \n",
            " activation_279 (Activation)    (None, 160, 64)      0           ['conv1d_293[0][0]']             \n",
            "                                                                                                  \n",
            " add_136 (Add)                  (None, 160, 64)      0           ['add_135[0][0]',                \n",
            "                                                                  'activation_279[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 160, 64)      0           ['add_136[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d_294 (Conv1D)            (None, 160, 32)      10272       ['dropout_6[0][0]']              \n",
            "                                                                                                  \n",
            " activation_280 (Activation)    (None, 160, 32)      0           ['conv1d_294[0][0]']             \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 160, 15)      495         ['activation_280[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 632,975\n",
            "Trainable params: 630,927\n",
            "Non-trainable params: 2,048\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 4.2683\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jdkEpng4AX_H"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}